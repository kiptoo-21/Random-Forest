# Random-Forest
In order to increase robustness compared to using a single estimator, ensemble techniques combine the predictions of multiple base estimators created using a specific learning algorithm. For regression and classification, ensemble techniques work best because they lower bias and variance and increase model accuracy. There are two ensemble techniques; bagging and boosting. This project will focus on bagging technique since it is used in the Random Forest model. Bagging is a homogeneous weak learner's model that joins the individual parallel learnings for the purpose of calculating the model average. This project will be working on a bank churn dataset. The aim of this project is to build ensemble models like Random Forest on the given dataset to determine whether the customer will churn or not. The language used for this project will be python. First the required libraries are imported. The dataset is then read. A train test split is performed. For the model buliding, a Random Forest model will be used. The feature importance is to create a function and find important features and to plot the features.
